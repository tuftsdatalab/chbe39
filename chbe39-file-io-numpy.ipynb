{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<p>\n",
    "<a href=\"https://colab.research.google.com/github/tuftsdatalab/chbe39/blob/master/chbe39-file-io-numpy.ipynb\" target=\"_blank\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://mybinder.org/v2/gh/tuftsdatalab/chbe39/master?urlpath=lab/tree/chbe39-file-io-numpy.ipynb\" target=\"_blank\">\n",
    "    <img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Launch Binder\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://cdn.jsdelivr.net/gh/tuftsdatalab/chbe39/chbe39-file-io-numpy.ipynb\" target=\"_blank\">\n",
    "    <img src=\"https://tuftsdatalab.github.io/assets/badges/jupyter.svg\" alt=\"Download Notebook\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://github.com/tuftsdatalab/chbe39\" target=\"_blank\">\n",
    "    <img src=\"https://tuftsdatalab.github.io/assets/badges/github.svg\" alt=\"View on GitHub\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://github.com/tuftsdatalab/chbe39/archive/master.zip\" target=\"_blank\">\n",
    "    <img src=\"https://tuftsdatalab.github.io/assets/badges/download.svg\" alt=\"Download Zip\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<span><img src=\"https://img.shields.io/github/repo-size/tuftsdatalab/chbe39?label=total%20size\" alt=\"total size\" style=\"float: left;\"/></span>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<span><img src=\"https://img.shields.io/github/last-commit/tuftsdatalab/chbe39?label=last%20updated\" alt=\"last updated\" style=\"float: left;\"/></span>\n",
    "</p>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DFAxibfbXbl"
   },
   "source": [
    "# ChBE-0039: File I/O with Python and NumPy\n",
    "\n",
    "---\n",
    "**A Tufts University Data Lab Workshop**\\\n",
    "Written by Uku-Kaspar Uustalu\n",
    "\n",
    "<html>\n",
    "<p>\n",
    "<a href=\"https://sites.tufts.edu/datalab/\" target=\"_blank\">\n",
    "        <img src=\"https://tuftsdatalab.github.io/assets/badges/datalab.svg\" alt=\"datalab.tufts.edu\" style=\"float: left;\"/></a>\n",
    "<span style=\"float:left;\">&ensp;</span>\n",
    "<a href=\"https://twitter.com/intent/follow?screen_name=tuftsdatalab\" target=\"_blank\">\n",
    "        <img src=\"https://tuftsdatalab.github.io/assets/badges/twitter.svg\" alt=\"@TuftsDataLab\" style=\"float: left;\"/></a>\n",
    "<br>\n",
    "</p>\n",
    "</html>\n",
    "\n",
    "Python resources: [go.tufts.edu/python](https://sites.tufts.edu/datalab/python/)\\\n",
    "Questions: [datalab-support@elist.tufts.edu](mailto:datalab-support@elist.tufts.edu)\\\n",
    "Feedback: [uku-kaspar.uustalu@tufts.edu](mailto:uku-kaspar.uustalu@tufts.edu)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab Setup\n",
    "If you are using Google Colab, please do the following **before proceeding**:\n",
    "1. If you are not already signed into your Google account, click on *Sign In* in the upper-right corner and sign in with your Google credentials. You must be signed in with a Google account to be able to run notebooks in Google Colab.\n",
    "2. Save a copy of the notebook to your Google Drive by clicking the *Copy to Drive* button above or selecting *File > Save a copy in Drive*. A copy of this notebook saved to your Google Drive will pop up. Close the original file and use the copy for the rest of the workshop. Now any changes you make will be saved to your Google Drive. Feel free to rename the copy if desired. You can still run the notebook without saving it to your Google Drive, but your progress and any changes you make will not be retained after you close the notebook.\n",
    "\n",
    "*You might also see a message warning you that this notebook was not authored by Google and hence might contain malicious code. You can trust Data Lab notebooks, so click __Run Anyway__. But when running other third-party notebooks, you should definitely review the code beforehand. __Do not run code you do not understand!__*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a NumPy Array to a File\n",
    "\n",
    "Once you are more comfortable with Python and NumPy arrays, it is highly likely that at some point you will have the need or desire to do one of the following:\n",
    "\n",
    "- Work with a preexisting dataset or matrix or save your results for future use\n",
    "- Export your results for publication or to share them with a friend or colleague\n",
    "- Conduct some parts of the analysis using a different program (like MATLAB)\n",
    "\n",
    "All of these situations involve writing a NumPy array to a file and/or reading a matrix from a file and saving it as a NumPy array. Luckily for you, NumPy has built-in functionality to accommodate this.\n",
    "\n",
    "Let's say we have an array `a` that we would like to export to a file for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option would be to use `np.save()` which saves the array to a binary `.npy` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('array1', a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you open the **File Browser** from the left-hand menu, you should now see `array1.npy` along with some other files.\n",
    "\n",
    "If you **downloaded** this notebook and are running it on a local instance of Jupyter, the `array1.npy` file is now saved into the same folder containing this notebook. You can use your system file browser (*Explorer* or *Finder*) to locate the file and take a look.\n",
    "\n",
    "If you are running this notebook using **Google Colab** or **Binder**, the `array1.npy` file is temporarily stored on the server running the notebook. You can view this the *only* using the built-in file browser accessible via the left-hand menu. Also note that this file along with any other files you might create will be deleted from the server after you close the notebook. You can download any files you would like to save on your computer by *right-clicking* on the file in the left-hand browser and then selecting *Download*.\n",
    "\n",
    "Note that if you try opening `array1.npy`, it will not work. That is because the file is in **binary** format, meaning it is not human-readable and can only be deciphered by NumPy. Saving NumPy arrays in binary format is a good option if you care about speed and efficiency and are only planning on using NumPy to work with the data.\n",
    "\n",
    "However, in many cases you might actually want to be able to see the contents of the file and use it with other programs like MATLAB. In that case, it makes much more sense to save the NumPy array as a human-readable text file. This can be done using `np.savetxt()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('array2.txt', a, fmt = '%.16e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bacause `array2.txt` is a human-readable text file, you can take a look at it by opening it with a text editor or *double-clicking* on it in the built-in file explorer on the left. Note how by default, the values are separated by spaces and the numbers are formatted using scientific notation.\n",
    "\n",
    "To change the separator between the array items in the outputted text file, we can use the `delimiter` argument. For example to produce a **CSV** (Comma-Separated Values) file, we can specify `delimiter = \",\"`.\n",
    "\n",
    "To change the formatting of the values themselves, we can use the `fmt` argument along with a ***format string***. Format strings are quite complex and can be very confusing to beginners. Assuming you will only be working with floating point numbers, here is a simple formula: `\"%.[precision][f|d]\"`\n",
    "\n",
    "- `precision` is the number of decimal points or significant digits\n",
    "- `f` stands for floating-point notation\n",
    "- `e` stands for scientific notation\n",
    "\n",
    "For example `\"%.9f\"` stands for floating-point notation with nine decimal points and `\"%.16e\"` stands for scientific notation with 16 significant digits (this is the default).\n",
    "\n",
    "If you would like to tweak the formatting even more, you can generate more complex format strings following this specification: https://docs.python.org/3/library/string.html#format-specification-mini-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('array3.csv', a, fmt = '%.12f', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at `array3.csv` and see how setting the delimiter and formatting string have changed the appearance of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reading a NumPy Array from a File\n",
    "\n",
    "To read a binary `.npy` file into a NumPy array, we can use `np.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('array1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read data from a text file into a NumPy array, we can use either `np.loadtxt()` or `np.genfromtxt()`. \n",
    "\n",
    "- `np.loadtxt` is an older function and provides very basic functionality\n",
    "- `np.genfromtxt()` is a newer and **faster** faster function that is more customizable and can handle missing values\n",
    "\n",
    "Hence it is recommended you use `np.genfromtxt()` as a default. When using either function, you have to specify the `delimiter` argument if using anything other than whitespace.\n",
    "\n",
    "A detailed guide on importing data with `np.genfromtxt()`: https://numpy.org/doc/stable/user/basics.io.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.loadtxt('array2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.genfromtxt('array3.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important thing to note when saving floating-point arrays to text files is ***loss of significance***. Because we can only store a set number of significant digits in the text file, it is possible that the number of significant digits will be reduced when writing data to a file, introducing round-off errors and causing precision loss.\n",
    "\n",
    "Note that this is not the case when using the binary `.npy` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing to a text file using the default setting of scientific notation with 16 significant digits, precision loss does not occur under normal circumstances. However, note that this is dependent on the *datatype* of your array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when specifying the number of decimal points or significant digits, or exporting with floating-point notation, precision loss is commonplace and very likely to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## File I/O With Python\n",
    "\n",
    "But what exactly happens when we use `np.genfromtxt()` to read data from a file? We can get a high-level overview of the mechanisms that take place in the background when we try to recreate the functionality using standard Python functionality.\n",
    "\n",
    "First, we have to open the file in order to be able to read data from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('array3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have  **file object** called `file` that gives us access to `array3.csv`. Using `.readlines()` with a file object, we can read all the lines from a file into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list called `lines`, where each element is a line from the file `array3.csv`. Note that some cleaning needs to be done as these lines still contain whitespace characters like newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    cleaned_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to convert each line to a list by splitting the string on the separator. This will lead to a list of lists, which is already quite similar to a two-dimensional NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for line in cleaned_lines:\n",
    "    lst = line.split(',')\n",
    "    lists.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how all the elements still have the type of `str`, meaning they are text, not numbers. Luckily there is an easy fix for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lists[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_lists = []\n",
    "for lst in lists:\n",
    "    flst = []\n",
    "    for element in lst:\n",
    "        element = float(element)\n",
    "        flst.append(element)\n",
    "    float_lists.append(flst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(float_lists[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this list of lists to create a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.array(float_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that we got the same result as we would have gotten using `np.genfromtxt()` by comparing it to the array `d` from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e == d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have to remember to close the file. This is very important to avoid any potential file corruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forgetting to close the file could lead to various issues and have serious consequences. Hence, it is commonplace to use `open()` in conjunction with a `with`statement. Any code executed within the block defined by the `with` statement has access to the file and any code outside of the block does not. This reduces the potential for errors and does not require you to use manually close the connection to the file.\n",
    "\n",
    "Also note how our previous processing involved looping over basically the same list numerous times. We can simplify this a little by looping over indices instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('array3.csv') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    lines[i] = lines[i].strip().split(',')\n",
    "    for j in range(len(lines[i])):\n",
    "        lines[i][j] = float(lines[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the result is indeed the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr == e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can condense this even more by using `map()` with `lambda` and remembering that `np.array()` has a `dtype` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('array3.csv') as f:\n",
    "    arr2 = np.array(list(map(lambda x : x.strip().split(','), f.readlines())), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr == arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as you can see, that already looks quite complicated and confusing. Plus, it is kind of ridiculous and completely unnecessary. Of course the easiest and most compact option would be to use `np.genfromtxt()` and that is what you should be using when attempting to read data from a text file into a NumPy array. As the saying goes, there is no point in reinventing the wheel.\n",
    "\n",
    "However, if you ever feel the need (or desire) to read a file line by line using Python, remember that a combination of `with`, `open()` and `.readlines()` is the easiest option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Resources:\n",
    "\n",
    "- Overview of all NumPy functions for reading and writing files: https://numpy.org/doc/stable/reference/routines.io.html\n",
    "- Detailed guide on importing data using `np.genfromtxt()`: https://numpy.org/doc/stable/user/basics.io.genfromtxt.html\n",
    "- Official Python tutorial on reading and writing files: https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
